{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802bae69",
   "metadata": {},
   "source": [
    "# 📄 Idea2Paper — Demo Notebook\n",
    "\n",
    "This notebook demonstrates the end-to-end pipeline of **Idea2Paper**:\n",
    "\n",
    "- LLM clarifier to structure messy notes\n",
    "- arXiv retrieval\n",
    "- SPECTER (sentence-transformers/allenai-specter) semantic ranking\n",
    "- PEGASUS-arXiv background summarization\n",
    "- Markdown draft generation with references\n",
    "\n",
    "> **Tip:** Ensure you ran `pip install -r requirements.txt` in your project root."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0681c7",
   "metadata": {},
   "source": [
    "## ✅ setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e764f60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\sivar\\Documents\\git\\Idea2Paper\n"
     ]
    }
   ],
   "source": [
    "# Make `src/` importable when running from the notebook folder\n",
    "import os, sys\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if root not in sys.path:\n",
    "    sys.path.insert(0, root)\n",
    "print(\"Project root:\", root)\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.config import (\n",
    "    MAX_ARXIV_RESULTS, TOP_K, SIM_THRESHOLD, EMBED_MODEL, SUM_MODEL, DEVICE, MAX_SUMMARY_LEN, DRAFT_DIR\n",
    ")\n",
    "from src.llm_interface import ClarifierLLM\n",
    "from src.retrieval import make_query_from_idea, fetch_arxiv\n",
    "from src.ranker import PaperRanker\n",
    "from src.summarizer import Summarizer\n",
    "from src.feasibility import quick_feasibility\n",
    "from src.generator import build_markdown, save_markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d95b2f",
   "metadata": {},
   "source": [
    "## ✍️ Provide your idea / notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd10afd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gravitational-wave tails and memory effect for mergers in astrophysical environments\n"
     ]
    }
   ],
   "source": [
    "# Edit this string with your own concept/notes\n",
    "idea = \"\"\"Gravitational-wave tails and memory effect for mergers in astrophysical environments\"\"\"\n",
    "\n",
    "print(idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ca14b3",
   "metadata": {},
   "source": [
    "## 🧩 Clarify and structure with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00defb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured fields:\n",
      "{'constraints': '',\n",
      " 'data': '',\n",
      " 'domain': '',\n",
      " 'hypothesis': '',\n",
      " 'keywords': ['gravitational-wave',\n",
      "              'tails',\n",
      "              'memory',\n",
      "              'effect',\n",
      "              'mergers',\n",
      "              'astrophysical',\n",
      "              'environments'],\n",
      " 'method': '',\n",
      " 'metrics': '',\n",
      " 'problem': 'Gravitational-wave tails and memory effect for mergers in astrophysical environments'}\n",
      "\n",
      "Clarifying questions:\n",
      "1. What is the exact domain/subfield?\n",
      "2. What is the main hypothesis or novelty?\n",
      "3. What method/architecture do you propose?\n",
      "4. Do you have any data or experimental results?\n",
      "5. How will you evaluate success (metrics/baselines)?\n"
     ]
    }
   ],
   "source": [
    "# Initialize the lightweight LLM (FLAN-T5 by default; falls back to heuristics if it can't load)\n",
    "llm = ClarifierLLM(device=DEVICE)\n",
    "\n",
    "# Turn raw notes into structured fields for the pipeline\n",
    "structured = llm.structure(idea)\n",
    "\n",
    "# Generate concise clarifying questions you can answer or incorporate into the fields\n",
    "questions = llm.followups(idea)\n",
    "\n",
    "print(\"Structured fields:\")\n",
    "pprint(structured, width=100)\n",
    "\n",
    "print(\"\\nClarifying questions:\")\n",
    "for i, q in enumerate(questions, 1):\n",
    "    print(f\"{i}. {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06644f7",
   "metadata": {},
   "source": [
    "## 🔎 Retrieve related papers from arXiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5868b67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ti:\"Gravitational-wave tails and memory effect for mergers in astrophysical environments gravitational-wave tails memory effect mergers astrophysical environments\" OR abs:\"Gravitational-wave tails and memory effect for mergers in astrophysical environments gravitational-wave tails memory effect mergers astrophysical environments\"\n",
      "Fetched 0 papers.\n",
      "No results. Try refining Domain/Problem/Keywords and re-run.\n"
     ]
    }
   ],
   "source": [
    "def build_search_query(struct: dict, fallback_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Compose a compact search string from the structured fields.\n",
    "    Falls back to the raw idea if fields are sparse.\n",
    "    \"\"\"\n",
    "    struct = struct or {}\n",
    "    parts = [\n",
    "        struct.get(\"domain\", \"\"),\n",
    "        struct.get(\"problem\", \"\"),\n",
    "        struct.get(\"hypothesis\", \"\"),\n",
    "        struct.get(\"method\", \"\"),\n",
    "        \" \".join(struct.get(\"keywords\", [])),\n",
    "    ]\n",
    "    q = \" \".join(p for p in parts if p).strip()\n",
    "    return q or (fallback_text.strip() if fallback_text else \"machine learning\")\n",
    "\n",
    "# Build a query from the structured fields (fallback to the raw idea)\n",
    "query_text = build_search_query(structured if isinstance(structured, dict) else {}, idea)\n",
    "query = make_query_from_idea(query_text)\n",
    "print(\"Query:\", query)\n",
    "\n",
    "# Fetch from arXiv\n",
    "try:\n",
    "    df = fetch_arxiv(query, max_results=MAX_ARXIV_RESULTS)\n",
    "    print(f\"Fetched {len(df)} papers.\")\n",
    "    if not df.empty:\n",
    "        display(df[[\"title\", \"published\", \"url\"]].head(10))\n",
    "    else:\n",
    "        print(\"No results. Try refining Domain/Problem/Keywords and re-run.\")\n",
    "except Exception as e:\n",
    "    print(\"Error fetching from arXiv:\", e)\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "# Optional: cache results for inspection\n",
    "# df.to_csv(\"data/papers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b7e69c",
   "metadata": {},
   "source": [
    "## 📈 Rank by semantic similarity (SPECTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a11b56d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No papers to rank. Run the arXiv retrieval step first.\n",
      "Mean similarity: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Guard: ensure we have retrieval results first\n",
    "if \"df\" not in globals() or df is None or df.empty:\n",
    "    print(\"No papers to rank. Run the arXiv retrieval step first.\")\n",
    "    ranked_df = pd.DataFrame()\n",
    "    mean_sim = 0.0\n",
    "else:\n",
    "    # Use the structured Problem (fallback to raw idea) as the target text\n",
    "    target_text = (structured.get(\"problem\") if isinstance(structured, dict) else None) or idea\n",
    "\n",
    "    # Rank with SPECTER embeddings\n",
    "    ranker = PaperRanker(EMBED_MODEL)\n",
    "    ranked_df, mean_sim = ranker.rank(target_text, df, top_k=TOP_K)\n",
    "\n",
    "    # Show top results\n",
    "    cols = [\"title\", \"published\", \"similarity\", \"url\"]\n",
    "    display(ranked_df[cols])\n",
    "\n",
    "print(\"Mean similarity:\", round(float(mean_sim), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56482026",
   "metadata": {},
   "source": [
    "## 🧪 Summarize background (PEGASUS-arXiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6528a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ranked papers to summarize. Run the retrieval & ranking steps first.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Guard: ensure we have ranked papers\n",
    "if \"ranked_df\" not in globals() or ranked_df is None or ranked_df.empty:\n",
    "    print(\"No ranked papers to summarize. Run the retrieval & ranking steps first.\")\n",
    "    background = \"\"\n",
    "else:\n",
    "    try:\n",
    "        # Concatenate title + abstract of top papers (limit to ~6 to stay within model context)\n",
    "        texts = (ranked_df[\"title\"] + \". \" + ranked_df[\"summary\"]).tolist()\n",
    "        joined = \" \".join(texts[: min(6, len(texts))])\n",
    "\n",
    "        # Initialize PEGASUS-arXiv summarizer\n",
    "        summarizer = Summarizer(model_name=SUM_MODEL, device=DEVICE)\n",
    "        background = summarizer.summarize(joined, max_len=MAX_SUMMARY_LEN)\n",
    "\n",
    "        print(\"=== Background & Related Work (summary) ===\\n\")\n",
    "        print(background)\n",
    "    except Exception as e:\n",
    "        print(\"Summarization skipped due to model load/error:\", e)\n",
    "        background = \"\"\n",
    "\n",
    "# Optional: keep for later cells\n",
    "# with open(\"outputs/background_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(background)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fae0ae",
   "metadata": {},
   "source": [
    "## ✅ Feasibility signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a07e73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Feasibility Signal ===\n",
      "❌ Very low plausibility: too vague or no related literature.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Choose the target text for feasibility (structured Problem → fallback to raw idea)\n",
    "target_text = (structured.get(\"problem\") if isinstance(structured, dict) else None) or idea\n",
    "\n",
    "# Use the mean similarity from the ranking step if available\n",
    "ms = float(mean_sim) if \"mean_sim\" in globals() else 0.0\n",
    "\n",
    "feas = quick_feasibility(\n",
    "    idea=target_text,\n",
    "    mean_similarity=ms,\n",
    "    sim_threshold=SIM_THRESHOLD\n",
    ")\n",
    "\n",
    "print(\"=== Feasibility Signal ===\")\n",
    "print(feas)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8bfe67",
   "metadata": {},
   "source": [
    "## 🧾 Generate Markdown draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f811981a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved draft to: drafts\\idea2paper_20250831_041912.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Idea2Paper Draft\n",
       "\n",
       "**Generated:** 2025-08-31 04:19 UTC\n",
       "\n",
       "## Abstract\n",
       "This work proposes a concept inspired by recent literature. We outline the core idea and potential impact.\n",
       "\n",
       "## Background & Related Work\n",
       "Relevant prior works indicate that this domain is active; a targeted literature review is recommended.\n",
       "\n",
       "## Proposed Method / Idea\n",
       "**Domain:**   \n",
       "**Problem:** Gravitational-wave tails and memory effect for mergers in astrophysical environments  \n",
       "**Hypothesis:**   \n",
       "**Method:**   \n",
       "**Data:**   \n",
       "**Metrics:**   \n",
       "**Constraints:**   \n",
       "**Keywords:** gravitational-wave, tails, memory, effect, mergers, astrophysical, environments\n",
       "\n",
       "## Expected Impact\n",
       "- Clarifies feasibility and boundary conditions  \n",
       "- Provides pathway to validation  \n",
       "- Potential to advance the state of the art  \n",
       "\n",
       "## Limitations\n",
       "- Draft generated by an automated assistant; verify all claims  \n",
       "- May miss non-arXiv or paywalled literature  \n",
       "- Requires expert review before submission  \n",
       "\n",
       "## Feasibility Signal\n",
       "❌ Very low plausibility: too vague or no related literature.\n",
       "\n",
       "## References\n",
       "- No references found.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Guards for previous steps\n",
    "if \"ranked_df\" not in globals() or ranked_df is None:\n",
    "    raise RuntimeError(\"No ranked_df found. Run retrieval & ranking first.\")\n",
    "if \"background\" not in globals():\n",
    "    background = \"\"\n",
    "if \"feas\" not in globals():\n",
    "    feas = \"⚠️ Feasibility not computed.\"\n",
    "\n",
    "# Use structured Problem if present, else raw idea\n",
    "problem_text = (structured.get(\"problem\") if isinstance(structured, dict) else None) or idea\n",
    "\n",
    "md = build_markdown(\n",
    "    idea=problem_text,\n",
    "    ranked_df=ranked_df if ranked_df is not None else pd.DataFrame(),\n",
    "    background_summary=background,\n",
    "    feasibility_text=feas,\n",
    "    structured_fields=structured if isinstance(structured, dict) else None,\n",
    ")\n",
    "\n",
    "path = save_markdown(md, DRAFT_DIR)\n",
    "print(\"Saved draft to:\", path)\n",
    "\n",
    "\n",
    "display(Markdown(md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e604c",
   "metadata": {},
   "source": [
    "## 🔎 Preview draft (render Markdown inline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e34f6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Idea2Paper Draft\n",
       "\n",
       "**Generated:** 2025-08-31 04:19 UTC\n",
       "\n",
       "## Abstract\n",
       "This work proposes a concept inspired by recent literature. We outline the core idea and potential impact.\n",
       "\n",
       "## Background & Related Work\n",
       "Relevant prior works indicate that this domain is active; a targeted literature review is recommended.\n",
       "\n",
       "## Proposed Method / Idea\n",
       "**Domain:**   \n",
       "**Problem:** Gravitational-wave tails and memory effect for mergers in astrophysical environments  \n",
       "**Hypothesis:**   \n",
       "**Method:**   \n",
       "**Data:**   \n",
       "**Metrics:**   \n",
       "**Constraints:**   \n",
       "**Keywords:** gravitational-wave, tails, memory, effect, mergers, astrophysical, environments\n",
       "\n",
       "## Expected Impact\n",
       "- Clarifies feasibility and boundary conditions  \n",
       "- Provides pathway to validation  \n",
       "- Potential to advance the state of the art  \n",
       "\n",
       "## Limitations\n",
       "- Draft generated by an automated assistant; verify all claims  \n",
       "- May miss non-arXiv or paywalled literature  \n",
       "- Requires expert review before submission  \n",
       "\n",
       "## Feasibility Signal\n",
       "❌ Very low plausibility: too vague or no related literature.\n",
       "\n",
       "## References\n",
       "- No references found.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Guard: ensure the Markdown string `md` exists\n",
    "try:\n",
    "    md  # noqa: F821\n",
    "except NameError:\n",
    "    raise RuntimeError(\"No Markdown draft found. Run the '🧾 Generate Markdown draft' step first.\")\n",
    "\n",
    "display(Markdown(md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252aef39",
   "metadata": {},
   "source": [
    "## 🚀 Next steps\n",
    "- Edit the structured fields and re-run the notebook cells to regenerate the draft.\n",
    "- Try a different idea, or add domain-specific keywords in the structured block.\n",
    "- Run the Streamlit app for a UI:  \n",
    "  ```bash\n",
    "  streamlit run src/app.py\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2168d4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sivar\\Documents\\git\\Idea2Paper\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.5.1+cu121 | cuda_available: True\n",
      "transformers: 4.56.0\n",
      "safetensors ok\n"
     ]
    }
   ],
   "source": [
    "import torch, transformers, safetensors\n",
    "print(\"torch:\", torch.__version__, \"| cuda_available:\", torch.cuda.is_available())\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"safetensors ok\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
